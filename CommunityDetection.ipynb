{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pickle5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mD:\\UNIVERSITA\\ESAMI DATI\\Network Science\\Community Detection\\utils.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m \n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdt\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle5\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m chain\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pickle5'"
     ]
    }
   ],
   "source": [
    "%run -i utils.py\n",
    "%run -i preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict of unique hashtag without 'redflag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00011-d25a8f35-e41e-4b47-8608-fdd2ffc7d264",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 407,
    "execution_start": 1638091951106,
    "source_hash": "523a1bc9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unique_hashtags = {}\n",
    "\n",
    "# for idx, row in tweets_filtered.iterrows():\n",
    "#     hashtag_list = []\n",
    "#     for hashtag in row[\"Hashtags\"]:\n",
    "#         hashtag = hashtag.lower()\n",
    "#         if hashtag in hashtags_list_list:\n",
    "#             unique_hashtags.setdefault(\"#\"+hashtag, 0)\n",
    "#             unique_hashtags['#'+hashtag] += 1\n",
    "#             hashtag_list.append(hashtag)\n",
    "#             tweets_filtered.at[idx, \"hashtags\"] = hashtag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00012-038f9553-31cb-413e-8a72-3601d757ca2a",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     382.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 53,
    "execution_start": 1638091955038,
    "source_hash": "8afe52ea",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m uh_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(unique_hashtags, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      2\u001b[0m uh_df\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mHashtag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m uh_df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m'\u001b[39m], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "uh_df = pd.DataFrame.from_dict(unique_hashtags, orient='index').reset_index()\n",
    "uh_df.rename(columns = {'index':'Hashtag', 0:'Count'}, inplace=True)\n",
    "uh_df.sort_values(by=['Count'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-1565c30e-99c3-4672-b386-e1cdfb64b975",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-21caa131-f1ef-4f45-845e-b96d18aaa76d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1638092045624,
    "source_hash": "377e708e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uh = unique_hashtags.keys()\n",
    "#uw = unique_words.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-465112bb-ce39-4737-b9a0-bd0f55807d11",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Hashtags Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00031-e7b37e35-937a-4d6c-9711-786427ba0701",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 909,
    "execution_start": 1638092046410,
    "source_hash": "af391030",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variable for filtering\n",
    "h = 0\n",
    "\n",
    "network = {} \n",
    "network_key = 0\n",
    "for index, row in tweets_filtered.iterrows():\n",
    "    #hashtags extracted from Tweet do not have the # sign in front of them but we will add it to differentiate hashtags from words\n",
    "    combined_list = ['#'+hashtag for hashtag in row[\"hashtags\"] if '#'+hashtag in unique_hashtags]\n",
    "    #itertool product creates Cartesian product of each element in the combined list (hastag + words, both UNIQUE)\n",
    "    for pair in itertools.product(combined_list, combined_list):\n",
    "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
    "        if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
    "            network.setdefault(pair, 0)\n",
    "            network[pair] += 1 \n",
    "\n",
    "network = {key: value for (key, value) in network.items() if value >= h} #filter the network\n",
    "network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
    "\n",
    "network_df.reset_index(inplace=True) \n",
    "network_df.columns = [\"pair\",\"weight\"] # undirected graph \n",
    "network_df.sort_values(by=\"weight\", inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00033-8d16ad0c-ef93-41f0-9cb3-75f29bb9ba03",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 170,
    "execution_start": 1638092056761,
    "source_hash": "b4499207",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#to get weighted graph we need a list of 3-element tuplels (u,v,w) where u and v are nodes and w is a number representing weight\n",
    "up_weighted = []\n",
    "for edge in network:\n",
    "    #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
    "    #if(network[edge])>1: \n",
    "    up_weighted.append((edge[0],edge[1],network[edge]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(up_weighted)\n",
    "\n",
    "hashtag_nodes = uh_df.copy()\n",
    "hashtag_nodes = hashtag_nodes.drop(hashtag_nodes[hashtag_nodes['Hashtag'] == '#redflag'].index)\n",
    "hashtag_nodes[\"Label\"] = hashtag_nodes[\"Hashtag\"]\n",
    "hashtag_nodes.rename(columns={\"Hashtag\":\"Id\"},inplace=True)\n",
    "hashtag_nodes = hashtag_nodes.drop(columns=['Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of nodes and number of unique_hashtags are different due to filter procedure. We only keep nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms, viz\n",
    "coms = algorithms.louvain(G, weight='weight', resolution=1., randomize=False)\n",
    "#coms = algorithms.surprise_communities(G)\n",
    "#coms = algorithms.leiden(G)\n",
    "#coms = algorithms.walktrap(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\network\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "hashtag_nodes['Modularity Class'] = 0\n",
    "\n",
    "k = 1\n",
    "for community in coms.communities:\n",
    "    for hashtag in hashtag_nodes['Label']:\n",
    "        if hashtag in community:\n",
    "            idx = hashtag_nodes[hashtag_nodes['Label'] == hashtag].index\n",
    "            hashtag_nodes['Modularity Class'][idx] = k\n",
    "    k += 1\n",
    "\n",
    "hashtag_nodes = hashtag_nodes.drop(hashtag_nodes[hashtag_nodes['Modularity Class'] == 0].index) # this is for remove nodes without edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node_list and Edge_list saving procedure for Gephi visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "00038-9029919b-4015-4d33-bb8e-621a8b0d1759",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1638034167298,
    "source_hash": "77ccd5a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo = '3'\n",
    "# SAVE NODE LIST\n",
    "hashtag_nodes.to_csv(\"./DATA_COMM/user/#nodelist_community_\" + algo +\".csv\", index=False)\n",
    "\n",
    "# We need to insert a column called \"Modularity Class\" and label\n",
    "file = pd.read_csv(\"./DATA_COMM/user/#nodelist_community_\" + algo +\".csv\", sep = \",\", header = 0, names = ['Id','Modularity Class'])\n",
    "file.insert(loc = 1, column = 'Label', value = file['Id'])\n",
    "file.to_csv(\"./DATA_COMM/user/#nodelist_community_\" + algo +\".csv\", index=False)\n",
    "\n",
    "nx.write_weighted_edgelist(G, \"./DATA_COMM/user/#edgelist_community_\" + algo +\".csv\")\n",
    "\n",
    "# We need to insert source, target, weight and type of edge\n",
    "file = pd.read_csv(\"./DATA_COMM/user/#edgelist_community_\" + algo +\".csv\", sep = \" \", header = 0, names = ['Source','Target','Weight'])\n",
    "file.insert(loc = 2, column = 'Type', value = ['undirected']*len(file))\n",
    "file.to_csv(\"./DATA_COMM/user/#edgelist_community_\" + algo +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by hashtags\n",
    "### Let's divide in community. In this case we choose the first one.\n",
    "Each modularity class is a community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtags_list = list(hashtag_nodes[hashtag_nodes['Modularity Class'] == 1]['Id'])\n",
    "# for i in range(len(hashtags_list)):\n",
    "#     hashtags_list[i] = hashtags_list[i][1:]\n",
    "\n",
    "# hashtags_list = ['covid19',\n",
    "#                  'gaslighting',\n",
    "#                  'plandemic',\n",
    "#                  'freedom',\n",
    "#                  'vaccines',\n",
    "#                  'truthmatters',\n",
    "#                  'covid',\n",
    "#                  'nonprofit',\n",
    "#                  'antivaxxers',\n",
    "#                  'community',\n",
    "#                  'education',\n",
    "#                  'science ']\n",
    "\n",
    "# hashtags_list = ['climatechange',\n",
    "#                  'climatecrisis',\n",
    "#                  'suistainable',\n",
    "#                  'savetheplanet',\n",
    "#                  'zerowaste',\n",
    "#                  'climatecrisis',\n",
    "#                  'climate']\n",
    "\n",
    "# hashtags_list = ['domesticviolence',\n",
    "#                  'domesticabuse',\n",
    "#                  'coercivecontrol',\n",
    "#                  'abuse',\n",
    "#                  'guncontrol',\n",
    "#                  '2a',\n",
    "#                  'guns',\n",
    "#                  'gunsense',\n",
    "#                  'redflaglaws']\n",
    "\n",
    "# hashtags_list = ['mentalhealth',\n",
    "#                  'health',\n",
    "#                  'feminism',\n",
    "#                  'toxic',\n",
    "#                  'mentalhealthmatters',\n",
    "#                  'selfcare',\n",
    "#                  'metoo',\n",
    "#                  'facts',\n",
    "#                  'girls',\n",
    "#                  'motivation',\n",
    "#                  'mentalhealthawereness',\n",
    "#                  'selflove',\n",
    "#                  'depression',\n",
    "#                  'run',\n",
    "#                  'meme',\n",
    "#                  'memes',\n",
    "#                  'blacktwitter',\n",
    "#                  'life',\n",
    "#                  'selfguarding',\n",
    "#                  'swipeleft',\n",
    "#                  'tinder',\n",
    "#                  'wtf',\n",
    "#                  'mindfulness',\n",
    "#                  'awereness',\n",
    "#                  'cannabiscommunity',\n",
    "#                  'cbd']\n",
    "\n",
    "# hashtags_list = ['dating',\n",
    "#                  'relationships',\n",
    "#                  'relationshipadvice',\n",
    "#                  'reallife',\n",
    "#                  'relatable',\n",
    "#                  'flag',\n",
    "#                  'stayway',\n",
    "#                  'funny',\n",
    "#                  'humor',\n",
    "#                  'datingadvice',\n",
    "#                  'datingtips',\n",
    "#                  'comedy',\n",
    "#                  'women',\n",
    "#                  'men',\n",
    "#                  'datingredflags',\n",
    "#                  'alert',\n",
    "#                  'lgtb',\n",
    "#                  'horoscope']\n",
    "\n",
    "hashtags_list = ['business',\n",
    "                 'digitalmarketing',\n",
    "                 'fraud',\n",
    "                 'trading',\n",
    "                 'money',\n",
    "                 'advice',\n",
    "                 'facebook',\n",
    "                 'twitter',\n",
    "                 'trend',\n",
    "                 'linkedin',\n",
    "                 'instagram',\n",
    "                 'entrepreneur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>989</td>\n",
       "      <td>2021-11-28 01:26:24+00:00</td>\n",
       "      <td>1464767600597082117</td>\n",
       "      <td>5 Red flags to watch out for at the beginning ...</td>\n",
       "      <td>RuthlessCI</td>\n",
       "      <td>[Relationship, RedFlag, Love, Advice, FairyTale]</td>\n",
       "      <td>red flag watch beginning relationship read ful...</td>\n",
       "      <td>[relationship, redflag, love, advice, fairytale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1141</td>\n",
       "      <td>2021-11-22 15:30:18+00:00</td>\n",
       "      <td>1462805647754514432</td>\n",
       "      <td>#BadData is no good. We at Merrill Research id...</td>\n",
       "      <td>ResearchMerrill</td>\n",
       "      <td>[BadData, data, business, RedFlag]</td>\n",
       "      <td>good research identify bad evaluate individual...</td>\n",
       "      <td>[baddata, data, business, redflag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1172</td>\n",
       "      <td>2021-11-21 01:26:22+00:00</td>\n",
       "      <td>1462230876683710467</td>\n",
       "      <td>Nobody's perfect.\\n\\nRead the full article: 5 ...</td>\n",
       "      <td>RuthlessCI</td>\n",
       "      <td>[Relationship, RedFlag, Love, Advice, FairyTale]</td>\n",
       "      <td>nobody perfect read full article reason prince...</td>\n",
       "      <td>[relationship, redflag, love, advice, fairytale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1209</td>\n",
       "      <td>2021-11-19 17:30:00+00:00</td>\n",
       "      <td>1461748607120461830</td>\n",
       "      <td>ðŸš©Be on the lookout for #accountingfraud red fl...</td>\n",
       "      <td>SurgentAFE</td>\n",
       "      <td>[accountingfraud, Surgent, fraud, financialsta...</td>\n",
       "      <td>lookout red flag offer content assess risk aud...</td>\n",
       "      <td>[accountingfraud, surgent, fraud, financialsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1282</td>\n",
       "      <td>2021-11-17 15:00:41+00:00</td>\n",
       "      <td>1460986255013990405</td>\n",
       "      <td>Don't do it to fit in do it because your finan...</td>\n",
       "      <td>hjmmanagement</td>\n",
       "      <td>[hjmman, hjmmanagement, redflag, trend, budget...</td>\n",
       "      <td>fit finance say</td>\n",
       "      <td>[hjmman, hjmmanagement, redflag, trend, budget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>5661</td>\n",
       "      <td>2021-10-05 14:28:19+00:00</td>\n",
       "      <td>1445395431136059396</td>\n",
       "      <td>Beware The Facebook \"Whistleblower\"! She Is A ...</td>\n",
       "      <td>PixelOkie</td>\n",
       "      <td>[DeleteFacebook, Facebook, facebookwhistleblow...</td>\n",
       "      <td>beware fraud plant demand censorship</td>\n",
       "      <td>[deletefacebook, facebook, facebookwhistleblow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>5816</td>\n",
       "      <td>2021-09-29 04:28:33+00:00</td>\n",
       "      <td>1443070168389734400</td>\n",
       "      <td>Dating #redflagðŸš©: someone who doesn't support ...</td>\n",
       "      <td>Cafe24_ph</td>\n",
       "      <td>[redflag, business, Cafe24, onlinebusiness]</td>\n",
       "      <td>date someone support support register</td>\n",
       "      <td>[redflag, business, cafe24, onlinebusiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>6199</td>\n",
       "      <td>2021-09-09 05:20:01+00:00</td>\n",
       "      <td>1435835363021438978</td>\n",
       "      <td>Clients who tell you a job should be \"easy\", \"...</td>\n",
       "      <td>lutrov</td>\n",
       "      <td>[redflag, webdev, webdesign, business]</td>\n",
       "      <td>client tell job easy simple quick rarely worth</td>\n",
       "      <td>[redflag, webdev, webdesign, business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>6205</td>\n",
       "      <td>2021-09-08 17:50:13+00:00</td>\n",
       "      <td>1435661768328564737</td>\n",
       "      <td>@VivintHome on what planet do u send people to...</td>\n",
       "      <td>DavidJKelley</td>\n",
       "      <td>[redflag, redflag, redflag, Fraud, SecurityRisk]</td>\n",
       "      <td>planet you send people someone house w appoint...</td>\n",
       "      <td>[redflag, redflag, redflag, fraud, securityrisk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>6453</td>\n",
       "      <td>2021-09-02 12:04:44+00:00</td>\n",
       "      <td>1433400496220430340</td>\n",
       "      <td>I joined Twitter because of @EricaNlewedim and...</td>\n",
       "      <td>ghailaclaire</td>\n",
       "      <td>[redflag, twitter, love]</td>\n",
       "      <td>join twitter today twitter anniversary trend t...</td>\n",
       "      <td>[redflag, twitter, love]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                  Datetime             Tweet Id  \\\n",
       "55      989 2021-11-28 01:26:24+00:00  1464767600597082117   \n",
       "207    1141 2021-11-22 15:30:18+00:00  1462805647754514432   \n",
       "238    1172 2021-11-21 01:26:22+00:00  1462230876683710467   \n",
       "275    1209 2021-11-19 17:30:00+00:00  1461748607120461830   \n",
       "348    1282 2021-11-17 15:00:41+00:00  1460986255013990405   \n",
       "...     ...                       ...                  ...   \n",
       "4727   5661 2021-10-05 14:28:19+00:00  1445395431136059396   \n",
       "4882   5816 2021-09-29 04:28:33+00:00  1443070168389734400   \n",
       "5265   6199 2021-09-09 05:20:01+00:00  1435835363021438978   \n",
       "5271   6205 2021-09-08 17:50:13+00:00  1435661768328564737   \n",
       "5519   6453 2021-09-02 12:04:44+00:00  1433400496220430340   \n",
       "\n",
       "                                                   Text         Username  \\\n",
       "55    5 Red flags to watch out for at the beginning ...       RuthlessCI   \n",
       "207   #BadData is no good. We at Merrill Research id...  ResearchMerrill   \n",
       "238   Nobody's perfect.\\n\\nRead the full article: 5 ...       RuthlessCI   \n",
       "275   ðŸš©Be on the lookout for #accountingfraud red fl...       SurgentAFE   \n",
       "348   Don't do it to fit in do it because your finan...    hjmmanagement   \n",
       "...                                                 ...              ...   \n",
       "4727  Beware The Facebook \"Whistleblower\"! She Is A ...        PixelOkie   \n",
       "4882  Dating #redflagðŸš©: someone who doesn't support ...        Cafe24_ph   \n",
       "5265  Clients who tell you a job should be \"easy\", \"...           lutrov   \n",
       "5271  @VivintHome on what planet do u send people to...     DavidJKelley   \n",
       "5519  I joined Twitter because of @EricaNlewedim and...     ghailaclaire   \n",
       "\n",
       "                                               Hashtags  \\\n",
       "55     [Relationship, RedFlag, Love, Advice, FairyTale]   \n",
       "207                  [BadData, data, business, RedFlag]   \n",
       "238    [Relationship, RedFlag, Love, Advice, FairyTale]   \n",
       "275   [accountingfraud, Surgent, fraud, financialsta...   \n",
       "348   [hjmman, hjmmanagement, redflag, trend, budget...   \n",
       "...                                                 ...   \n",
       "4727  [DeleteFacebook, Facebook, facebookwhistleblow...   \n",
       "4882        [redflag, business, Cafe24, onlinebusiness]   \n",
       "5265             [redflag, webdev, webdesign, business]   \n",
       "5271   [redflag, redflag, redflag, Fraud, SecurityRisk]   \n",
       "5519                           [redflag, twitter, love]   \n",
       "\n",
       "                                             clean_text  \\\n",
       "55    red flag watch beginning relationship read ful...   \n",
       "207   good research identify bad evaluate individual...   \n",
       "238   nobody perfect read full article reason prince...   \n",
       "275   lookout red flag offer content assess risk aud...   \n",
       "348                                     fit finance say   \n",
       "...                                                 ...   \n",
       "4727               beware fraud plant demand censorship   \n",
       "4882              date someone support support register   \n",
       "5265     client tell job easy simple quick rarely worth   \n",
       "5271  planet you send people someone house w appoint...   \n",
       "5519  join twitter today twitter anniversary trend t...   \n",
       "\n",
       "                                               hashtags  \n",
       "55     [relationship, redflag, love, advice, fairytale]  \n",
       "207                  [baddata, data, business, redflag]  \n",
       "238    [relationship, redflag, love, advice, fairytale]  \n",
       "275   [accountingfraud, surgent, fraud, financialsta...  \n",
       "348   [hjmman, hjmmanagement, redflag, trend, budget...  \n",
       "...                                                 ...  \n",
       "4727  [deletefacebook, facebook, facebookwhistleblow...  \n",
       "4882        [redflag, business, cafe24, onlinebusiness]  \n",
       "5265             [redflag, webdev, webdesign, business]  \n",
       "5271   [redflag, redflag, redflag, fraud, securityrisk]  \n",
       "5519                           [redflag, twitter, love]  \n",
       "\n",
       "[80 rows x 8 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_comm = tweets_filtered.copy().reset_index()\n",
    "# Procedure to filtrate only tweets with hashtag inside the community\n",
    "tweets_comm = tweets_filtered.copy().reset_index()\n",
    "idx_list = []\n",
    "for c in hashtags_list:\n",
    "    idx_list.append(list(tweets_comm[tweets_comm['hashtags'].apply(lambda x: c in x)].index))\n",
    "idx = np.unique(list(chain(*idx_list)))\n",
    "tweets_comm = tweets_comm.iloc[list(idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique words in community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_id": "00008-fc76d07a-33b3-49a0-b457-ec409e18fad6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1638091758876,
    "source_hash": "8e9463a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Where are we working:\n",
    "dataframe = tweets_comm.copy()\n",
    "#initialize an empty dict  \n",
    "unique_words = {} \n",
    "for row in dataframe.clean_text:\n",
    "    for word in row.split(\" \"):\n",
    "        #if the word is encountered for the first time add to dict as key and set its value to 0\n",
    "        unique_words.setdefault(word,0)\n",
    "        #increase the value (i.e the count) of the word by 1 every time it is encountered\n",
    "        unique_words[word] += 1 # get unique words and their frequences\n",
    "word_nodes = pd.DataFrame.from_dict(unique_words, orient=\"index\")\n",
    "word_nodes.reset_index(inplace=True)\n",
    "word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
    "word_nodes.rename(columns={\"index\":\"Id\", 0:\"delete\"},inplace=True)\n",
    "word_nodes = word_nodes.drop(columns=['delete']) \n",
    "\n",
    "uw_df = pd.DataFrame.from_dict(unique_words, orient='index').reset_index()\n",
    "uw_df.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
    "uw_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
    "uw = unique_words.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "cell_id": "00020-f9e09c6f-a742-42b1-979a-96c463dfa2de",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 909,
    "execution_start": 1638092046410,
    "source_hash": "af391030",
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = 0\n",
    "network = {} \n",
    "network_key = 0\n",
    "for index, row in dataframe.iterrows():\n",
    "    #hashtags extracted from Tweet do not have the # sign in front of them but we will add it to differentiate hashtags from words\n",
    "    combined_list = [word for word in str.split(row[\"clean_text\"], \" \") if word in uw]\n",
    "    #itertool product creates Cartesian product of each element in the combined list (hastag + words, both UNIQUE)\n",
    "    for pair in itertools.product(combined_list, combined_list):\n",
    "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
    "        if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
    "            network.setdefault(pair, 0)\n",
    "            network[pair] += 1 \n",
    "\n",
    "#network = {key: value for (key, value) in network.items() if value >= h} #filter the network\n",
    "network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
    "\n",
    "network_df.reset_index(inplace=True) \n",
    "network_df.columns = [\"pair\",\"weight\"] # undirected graph \n",
    "\n",
    "#to get weighted graph we need a list of 3-element tuplels (u,v,w) where u and v are nodes and w is a number representing weight\n",
    "up_weighted = []\n",
    "for edge in network:\n",
    "    #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
    "    #if(network[edge])>1: \n",
    "    up_weighted.append((edge[0],edge[1],network[edge]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(up_weighted)\n",
    "\n",
    "to_remove = list(set(list(word_nodes['Id'])) ^ set(list(G.nodes())))\n",
    "for i in range(len(to_remove)):\n",
    "    word_nodes = word_nodes.drop(word_nodes[word_nodes['Id'] == to_remove[i]].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node_list and Edge_list saving procedure for Gephi visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./DATA_COMM/\"\n",
    "comm = '12'\n",
    "\n",
    "# SAVE NODE LIST\n",
    "word_nodes.to_csv(path + \"#nodelist_community\"+comm+\".csv\", index=False) \n",
    "\n",
    "# We need to insert a column called \"Modularity Class\" and label\n",
    "file = pd.read_csv(path + \"#nodelist_community\"+comm+\".csv\", sep = \",\", header = 0, names = ['Id','Modularity Class'])\n",
    "file.insert(loc = 1, column = 'Label', value = file['Id'])\n",
    "file.to_csv(path + \"#nodelist_community\"+comm+\".csv\", index=False)\n",
    "\n",
    "nx.write_weighted_edgelist(G, path + \"#edgelist_community\"+comm+\".csv\")\n",
    "\n",
    "# We need to insert source, target, weight and type of edge\n",
    "file = pd.read_csv(path + \"#edgelist_community\"+comm+\".csv\", sep = \" \", header = 0, names = ['Source','Target','Weight'])\n",
    "file.insert(loc = 2, column = 'Type', value = ['undirected']*len(file))\n",
    "file.to_csv(path + \"#edgelist_community\"+comm+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "da2a713b-c1a6-40e5-9249-e5fce1d1cb07",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
